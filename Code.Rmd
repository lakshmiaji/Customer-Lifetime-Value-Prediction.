---
title: "Customer Lifetime Value Analysis Report"
output: html_document
---

# TEAM 3 : Pi-oneers 

## The Fellowship of the errors.

## Group Members

- Marion - 20BDA04

- Bismi - 20BDA07

- Lakshmi - 20BDA09

- Glennis - 20BDA24

- Gargi - 20BDA55

- Ajay - 20BDA64


# INTRODUCTION

    It is in the best interest of a company to know what makes a customer more valuable and how not to lose these valuable customers. Henceforth, companies use ‘Customer Lifetime Value’. The Customer Lifetime Value (‘CLV’) is an estimate of how valuable a customer is to a company. In other words, the higher the customer's lifetime value, the more business they provide the company in their lifetime. It is necessary to identify the key features that contribute to the ‘CLV’ and understand how these key features affect ‘CLV’ , to maximize profit for a company.

    We use the ‘IBM Watson Marketing Customer Value Data’ to analyse factors that may help us to understand CLV better. This dataset is a vehicle insurance data, consisting of 9134 rows collected in 5 states of the USA [Arizona, California, Nevada, Oregon, Washington] throughout the months of January and February in the year 2011.

    In this report we’ll first see the effects of different variables on CLV and we’ll compare multiple models to predict CLV and propose a final model to predict CLV.

## Dataset Description

    In the dataset there are 9134 observations and 24 variables. The dependent variable is  Customer.Lifetime.Value. The independent variables are:

- Customer (Unique ID assigned to customers).

- State (State to which customers belong).
  
  - Arizona, Nevada, Oregon, California, Washington
 
- Customer Lifetime Value (Net profit generated by customers for the firm).

- Response(Positive or negative response with regards to purchase of policy plans).
  
  - No, Yes
  
- Coverage (Policy coverage chosen by the customers).
  
  - Basic, Extended, Premium

- Education (Education received by the customers).
  
  - Bachelor, College, Doctor, HighSchool or Below, Master

- Effective To Date (Maturity date of insurance policy plan).

- EmploymentStatus (Customers' current employment status).
  
  - Employed, Unemployed, Disabled, Retired, Medical Leave

- Gender (Gender of customers).
  
  - F(Female), M(Male)

- Income (Income level of cusomers).

- Location Code	(Type of residential area of cusomers).
  
  - Rural, Suburban, Urban

- Marital Status (Relationship status).
  
  - Divorced, Married, Single

- Monthly Premium Auto (Monthly premium paid for the policy).

- Months Since Last Claim (Number of months that passed since the last claim made by the customer).

- Months Since Policy Inception	(Number of months since the activation of policy plan).

- Number of Open Complaints	(Number of unsolved complaints made by the customer).

- Number of Policies (Total number of policies purchased).

- Policy Type (Type of policy under the main categories).

  - Corporate Auto, Personel Auto, Special Auto

- Policy (Category of policy plan adopted by the customer).

  - personal L1, personel L2, personel L3, corporate L1, corporate L2, corporate L3, special L1, special L2, special L3

- Renew Offer Type (Class of renewal offer accepted by the customer).
  
  - offer 1, offer 2, offer 3, offer 4

- Sales Channel	(Channel via sales with a particular customer occurred).
  - Agent, Branch, Call centre, Web

- Total Claim Amount(Total amount that can be claimed by the customer on/before policy maturity).

- Vehicle Class (Class to which the insured vehicle belongs).
  
  - Four-Door-Car, Luxury car, Luxury SUV, Sports Car, SUV, Two-Door-Car

- Vehicle Size (Size of the customers' insured vehicle).

    Out of which 14 are categorical, 6 integers and 1 numerical.

## Objective - Predict Customer Lifetime Value of a vehicle insurance company.


### Installing packages required

```{r}

#1. Hmisc
library(Hmisc)
#2. ggplot2
library(ggplot2)
#3.tidyverse
library(tidyverse)
#4.MASS
library(MASS)  # for stepAIC
#5.psych
library(psych)  # for describe
#6.modelr
library(modelr) # for r squared
#7.randomForest
library(randomForest)  #for random forest
#8.klaR
library(klaR)
#9.dplyr
library(dplyr)
#10.caret
library(caret)
#11.car
library(car)



```
### Loading data

```{r}

#Setting path
setwd('C:/Users/ajiva/Desktop/Akhileswar')


#Importing data 
data <- read.csv('CLVdata.csv',
                 header=TRUE)

head(data)

```


```{r}
#Viewing Data
View(data)

#Checking for missing values
colSums(is.na(data)) 

#Summary of data
str(data)
summary(data)

```


## EDA

Here we perform summary statistics and graphical representations on insurance data, to get better understanding and insights.

Decriptive Analysis of Customer Lifetime Value(CLV)

```{r}
describe(data$Customer.Lifetime.Value)
```

```{r}

hist(data$Customer.Lifetime.Value,
     breaks = (max(data$Customer.Lifetime.Value) - min(data$Customer.Lifetime.Value))/100,
     main = "Histogram of CLV", 
     xlab = "CLV", 
     border = "darkolivegreen3")

```

    The distribution is positively skewed. Most values lie towards left. Maximum CLV is 83325.381. Minimum CLV is 1898.008. Mean value is 8005, Median is 5780.
    From this we can say that company makes a lot of business with few high range customers. A loss of few of these customers would have a similar impact to that of a loss of many of low paying customers.

```{r}

ggplot(data=data) +
  aes(x = "", y = Customer.Lifetime.Value) +
  geom_boxplot(fill = "darkolivegreen3") +
  theme_minimal()+
  labs(title="Boxplot of CLV")

```


```{r}
outlier_percent <- function(x){
  length(which(x >  mean(x) + 3 * sd(x) | x < mean(x) - 3 * sd(x))  ) / length(x)
}
outlier_percent(data$Customer.Lifetime.Value)
```


    Observed 2.3% of outliers in CLV column. There are two ways to deal with it. One is log transformation and the other is clipping.


```{r}

options(repr.plot.width=5, repr.plot.height=4)
hist(log1p(data$Customer.Lifetime.Value),
     breaks = (max(data$Customer.Lifetime.Value) - min(data$Customer.Lifetime.Value))/100,
     main = "Histogram of CLV", 
     xlab = "CLV", 
     border = "darkolivegreen3")

```


    Taking natural logarithm of values, can eliminate the effect of outliers upto certain extent as able to get less skewed distribution.


#### EDA of numerical variables.

##### Monthly Premium 

```{r}
options(repr.plot.width=5, repr.plot.height=5)
hist(data$Monthly.Premium.Auto,
     breaks = (max(data$Monthly.Premium.Auto) - min(data$Monthly.Premium.Auto))/10,
     main = "Histogram of Monthly Premium", 
     xlab = "Monthly Premium", 
     border = "darkolivegreen3")
```

      The distribution is positively skewed and most values and concentrated on the left side.
      Maximum MPA is 298 and Minimum is 61.

```{r}

ggplot(data=data) +
  aes(x = "", y = Monthly.Premium.Auto) +
  geom_boxplot(fill = "darkolivegreen3") +
  theme_minimal()+
  labs(title="Boxplot of Monthly Premium")

```


```{r}
outlier_percent(data$Monthly.Premium.Auto)
```

    2.18 % of outliers present.

```{r}
options(repr.plot.width=5, repr.plot.height=4)
hist(log1p(data$Monthly.Premium.Auto),
     breaks = (max(data$Monthly.Premium.Auto) - min(data$Monthly.Premium.Auto))/10,
     main = "Histogram of Monthly Premium", 
     xlab = "Monthly Premium", 
     border = "darkolivegreen3")

```

##### Total Claim Amount 

```{r}
options(repr.plot.width=5, repr.plot.height=5)
hist(data$Total.Claim.Amount,
     breaks = (max(data$Total.Claim.Amount) - min(data$Total.Claim.Amount))/100,
     main = "Histogram of Total Claim Amount", 
     xlab = "Total Claim Amount", 
     border = "darkolivegreen3")
```

     The distribution is positively skewed and most values and concentrated on the left side.
     Maximum TCA is 2893.24 and minimum is 0.0990.

```{r}

ggplot(data=data) +
  aes(x = "", y = Total.Claim.Amount) +
  geom_boxplot(fill = "darkolivegreen3") +
  theme_minimal()+
  labs(title="Boxplot of Total Claim Amount")

```

```{r}
outlier_percent(data$Total.Claim.Amount)
```

    1.7% of outliers present.


##### Income

```{r}

options(repr.plot.width=5, repr.plot.height=4)
data %>%
  ggplot( aes(x=Income)) + 
  geom_density(fill="darkolivegreen3", color="grey", alpha=0.8)+
  labs(title="Density Plot of Income")

```

    Here we see a right skewed distribution as expected for an income distribution. But we see an unusually high amount of zero income as a high number of the customers in this population are unemployed (Students).

```{r}
CLVIncome <- ggplot(data, aes(x=Income, y=Customer.Lifetime.Value,)) +
  geom_point( color="navyblue") +
  geom_smooth(method=lm , color="red", fill="blue", se=TRUE)+
  labs(title = "CLV vs Income")
CLVIncome
```


    Valuable customers are not decided by their income. The red line here is a regression line, indicating regression between customer lifetime value (dependent) and income (independent).


#### EDA for Categorical Variables


```{r}
options(repr.plot.width=7, repr.plot.height=4)
GraphNumComplaints <- ggplot(data, aes(x=Number.of.Open.Complaints)) + 
geom_bar(stat = "count", position = "dodge")+
  labs(title="Frequency of Open complaints",
       x="Open Complaints",
       y="Frequency")

GraphNumComplaints

```
        
        
        Most customers have zero complaints.

```{r}
options(repr.plot.width=7, repr.plot.height=4)
GraphNumComplaints <- ggplot(data, aes(x=Number.of.Open.Complaints, y=Customer.Lifetime.Value, 
fill = Number.of.Open.Complaints)) + 
geom_bar(stat = "summary",fun="mean")+
  labs(title="Avg CLV Vs No of open complaints")

GraphNumComplaints

```

    Customers who complaints more are observed to be less valuable.

```{r}

options(repr.plot.width=7, repr.plot.height=4)
GraphNumPols <- ggplot(data, aes(x=Number.of.Policies)) + 
geom_bar(stat = "count",position="dodge")+
  labs(title="Frequency of policies",
       x=" Number of Policy",
       y="Frequency")

GraphNumPols
```

    
```{r}
options(repr.plot.width=7, repr.plot.height=4)
GraphNumPols <- ggplot(data, aes(x=Number.of.Policies, y=Customer.Lifetime.Value, fill = Number.of.Policies)) + 
geom_bar(stat = "summary",fun="mean")+
  labs(title="Avg CLV Vs number of policies",
       x=" Number of Policy",
       y="Customer Lifetime Value")
  

GraphNumPols
```


     The customers holding two policies are expected to be more valuable than customers holding higher than two. Least valuable customers are those with only one policy. 

```{r}
options(repr.plot.width=7, repr.plot.height=4)
GraphEmpStatus <- ggplot(data, aes(x=EmploymentStatus, fill = EmploymentStatus)) + 
geom_bar(stat = "count")+
  labs(title="Frequency of EmploymentStatus",
       x="Employment Status",
       y="Frequency")

GraphEmpStatus
```

```{r}
options(repr.plot.width=7, repr.plot.height=4)
GraphEmpStatus <- ggplot(data, aes(x=EmploymentStatus, y=Customer.Lifetime.Value, fill = EmploymentStatus)) + 
geom_bar(stat = "summary",fun="median")+
 labs(title=" CLV Vs EmploymentStatus",
       x="Employment Status",
       y="Customer Lifetime Value") 

GraphEmpStatus
```


    Average CLV of customers more or less similar irrespective of their employment status.           Employment status of the customers doesn't effect their value.


```{r}
options(repr.plot.width=7, repr.plot.height=4)
GraphCoverage <- ggplot(data, aes(x=Coverage,  fill = Coverage)) + 
geom_bar(stat = "count")+
  labs(title = "Frequency of Coverage",
       x="Coverage",
       y="Frequency")

GraphCoverage

```


```{r}

options(repr.plot.width=7, repr.plot.height=4)
GraphCoverage <- ggplot(data, aes(x=Coverage, y=Customer.Lifetime.Value, fill = Coverage)) + 
geom_bar(stat = "summary",fun="median")+
  labs(title = " CLV Vs Coverage",
       x="Coverage",
       y="Customer Lifetime Value")
  

GraphCoverage

```

     Customers paying for a higher coverage are more valuable.
     

```{r}
options(repr.plot.width=7, repr.plot.height=4)
GraphResponse <- ggplot(data, aes(x=Response,  fill = Response)) + 
geom_bar(stat = "count")+
  labs(title="Frequency of Response",
       x="Response",
       y="Frequency")

GraphResponse
```

      Most of the customers are unhappy/unsatisfied with their purchase of the policy.

```{r}
options(repr.plot.width=7, repr.plot.height=4)
GraphResponse <- ggplot(data, aes(x=Response, y=Customer.Lifetime.Value, fill = Response)) + 
geom_bar(stat = "summary",fun="mean")+
  labs(title="Avg CLV Vs Response",
       x="Response",
       y="Customer Lifetime Value")
  

GraphResponse

```

```{r}

options(repr.plot.width=5, repr.plot.height=4)
data %>%
  ggplot( aes(x=Customer.Lifetime.Value)) + 
  facet_wrap(~Response)+
  geom_density(fill="darkolivegreen3", color="grey", alpha=0.8)+
  labs(title="Density Plot of CLV with respect to Response",
       x="Customer Lifetime Value")

```


     Most customers had given negative response but satisfaction of a customer doesn't influence thier value. In other words, a satisfied customer on an average will spend same as that of an unsatified customer.


```{r}
options(repr.plot.width=7, repr.plot.height=4)
GraphState <- ggplot(data, aes(x=State, fill = State)) + 
geom_bar(stat = "count")+
  labs(title="Frequency of State",
       y="Frequency")

GraphState
```

```{r}
options(repr.plot.width=7, repr.plot.height=4)
GraphState <- ggplot(data, aes(x=State, y=Customer.Lifetime.Value, fill = State)) + 
geom_bar(stat = "summary",fun="mean")+
  labs(title="Avg CLV Vs State",
       y="Customer Lifetime Value")

GraphState
```

    Most of the customers reported are from California and Oregon, but doesn't make sense if we say more valuable customers are from there.

```{r}
GraphMF <- ggplot(data, aes(x=Gender,  fill = Gender)) + 
geom_bar(stat = "count") +
labs(x="Gender",y = "Customer Life Time Value", fill="Gender") + 
  ggtitle("Frequency of  Gender")

GraphMF
```

```{r}
GraphMF <- ggplot(data, aes(x=Gender, y=Customer.Lifetime.Value, fill = Gender)) + 
geom_bar(stat = "summary",fun="median") +
labs(x="Gender",y = "Customer Life Time Value", fill="Gender") + 
  ggtitle("Avg CLV Vs Gender")

GraphMF
```

    
    
    
```{r}

options(repr.plot.width=5, repr.plot.height=4)
data %>%
  ggplot( aes(x=Customer.Lifetime.Value)) + 
  facet_wrap(~Gender)+
  geom_density(fill="darkolivegreen3", color="grey", alpha=0.8)+
  labs(title="Density Plot of CLV with respect to Gender", x="Customer Lifetime Value")

```

    
    Both Male and Female customers are equally valuable.


```{r}
options(repr.plot.width=7, repr.plot.height=4)
GraphEdu <- ggplot(data, aes(x=Education, fill = Education)) + 
geom_bar(stat = "count")+
  labs(title="Frequency of Education",y="Frequency")

GraphEdu
```

    Most customers with education bachelor, college and highschool.
    
```{r}
options(repr.plot.width=7, repr.plot.height=4)
GraphEdu <- ggplot(data, aes(x=Education, y=Customer.Lifetime.Value, fill = Education)) + 
geom_bar(stat = "summary",fun="mean")+
  labs("Avg CLV Vs Education",y="Customer Lifetime Value")

GraphEdu
```


    Education doesn't influence their CLV value. 

```{r}
options(repr.plot.width=7, repr.plot.height=4)
GraphLocCode <- ggplot(data, aes(x=Location.Code, y=Customer.Lifetime.Value, fill = Location.Code)) + 
geom_bar(stat = "identity") +
labs(x="Location Code",y = "Customer Life Time Value", fill="Location.Code") + 
  ggtitle("CLV Vs Location")

GraphLocCode
```

    More customers are from suburban areas.

```{r}
options(repr.plot.width=7, repr.plot.height=4)
GraphLocCode <- ggplot(data, aes(x=Location.Code, y=Customer.Lifetime.Value, fill = Location.Code)) + 
geom_bar(stat = "summary",fun="mean") +
labs(x="Location Code",y = "Customer Life Time Value", fill="Location.Code") + 
  ggtitle("Avg CLV Vs Location")

GraphLocCode
```

 
    Location to which they belong doesn't make them more valuable.

```{r}
options(repr.plot.width=7, repr.plot.height=4)
GraphMarStat <- ggplot(data, aes(x=Marital.Status, fill = Marital.Status)) + 
geom_bar(stat = "count")+
  labs(title="Frequency of Marital Status",
       x="Marital Status",
       y="Frequency")

GraphMarStat
```

```{r}
options(repr.plot.width=7, repr.plot.height=4)
GraphMarStat <- ggplot(data, aes(x=Marital.Status, y=Customer.Lifetime.Value, fill = Marital.Status)) + 
geom_bar(stat = "summary",fun="median")+
  labs(title="CLV Vs Marital Status",x="Marital Status",
       y="Customer Lifetime Value")

GraphMarStat
```

    Most of the customers are married, but their marital status doesn't influence whether they are valuable or not. 

```{r}
options(repr.plot.width=7, repr.plot.height=4)
GraphRenewOff <- ggplot(data, aes(x=Renew.Offer.Type, fill = Renew.Offer.Type)) + 
geom_bar(stat = "count")+
  labs(title="Frequency of Renew Offer type",
       x="Renew offer type",
       y="Frequency")
GraphRenewOff
```

```{r}
options(repr.plot.width=7, repr.plot.height=4)
GraphRenewOff <- ggplot(data, aes(x=Renew.Offer.Type, y=Customer.Lifetime.Value, fill = Renew.Offer.Type)) + 
geom_bar(stat = "summary",fun="mean")+
  labs(title="Avg CLV Vs Renew Offer Type",
       x="Renew offer type",
       y="Customer Lifetime Value")
GraphRenewOff
```

    Most Customers accepted renewal offer type1 and they are more valuable compared to other customers who choose the remaining offers.

```{r}
options(repr.plot.width=7, repr.plot.height=4)
GraphSalesCh <- ggplot(data, aes(x=Sales.Channel, fill = Sales.Channel)) + 
geom_bar(stat = "count")+
  labs(title="Frequency of Sales Channel",
       x="Sales Channel",
       y="Frequency")
  

GraphSalesCh
```

```{r}
options(repr.plot.width=7, repr.plot.height=4)
GraphSalesCh <- ggplot(data, aes(x=Sales.Channel, y=Customer.Lifetime.Value, fill = Sales.Channel)) + 
geom_bar(stat = "summary",fun="mean")+
  labs(title="Avg CLV Vs Sales Channel",x="Sales Channel",y="Customer Lifetime Value")

GraphSalesCh
```

    Good proportion of customers got in because of agents.
    But their CLV is not significantly influenced by the sales channel. 

```{r}
options(repr.plot.width=7, repr.plot.height=4)
GraphVecClass <- ggplot(data, aes(x=Vehicle.Class,  fill = Vehicle.Class)) + 
geom_bar(stat = "count")+
  labs(title="Frequency of Vehicle Class",
       x="Vehicle Class",
       y="Frequency")
GraphVecClass
```

    Most Customers had taken policy for Four-Door-Cars.

```{r}
options(repr.plot.width=20, repr.plot.height=4)
GraphVecClass <- ggplot(data, aes(x=Vehicle.Class, y=Customer.Lifetime.Value, fill = Vehicle.Class)) + 
geom_bar(stat = "summary",fun="median")+
  labs(title="CLV Vs Vehicle Class",
       x="Vehicle Class",
       y="Customer Lifetime Value")
GraphVecClass
```



    But Customers who took policy for Luxury Car and Luxury SUV are expected to be more valuable compared to the rest. This is likely because the higher is the value of the vehicles, higher the value of the policy.

```{r}
options(repr.plot.width=7, repr.plot.height=4)
GraphVecSize <- ggplot(data, aes(x=Vehicle.Size, fill = Vehicle.Size)) + 
geom_bar(stat = "count")+
  labs(title="Frequency of Vehicle Size",
       x="Vehicle Size",
       y="Frequency")

GraphVecSize
```

```{r}
options(repr.plot.width=7, repr.plot.height=4)
GraphVecSize <- ggplot(data, aes(x=Vehicle.Size, y=Customer.Lifetime.Value, fill = Vehicle.Size)) + 
geom_bar(stat = "summary",fun="mean")+
  labs(title="Avg CLV Vs Vehicle Size",
       x="Vehicle Size",
       y="Customer Lifetime Value")

GraphVecSize
```

    Midsize vehicles were more owned by the customers.
    Vehicle size doesn't influence much on their Customer Lifetime Value.

```{r}
options(repr.plot.width=9, repr.plot.height=4)
GraphPolicy <- ggplot(data, aes(x=Policy, fill = Policy)) + 
geom_bar(stat = "count")+
  labs(title="Frequency of Policy",
       y="Frequency")

GraphPolicy
```
```{r}
#With respect to Monthly Auto
ggplot(data=data, aes(y=Customer.Lifetime.Value, x=Monthly.Premium.Auto, color=Response ))+
  geom_point()+
  facet_wrap(~Policy)+
  labs(title="Distribution of CLV vs Monthly", 
       subtitle="With respect to Policy",
       fill="Response",
       y="CLV",
       x="Monthly Premium")
       
```


```{r}
#With respect to Policy
ggplot(data=data, aes(y=Customer.Lifetime.Value, x=Monthly.Premium.Auto, color=Response ))+
  geom_point()+
  ylim(c(0,40000))+
  facet_wrap(~Policy)+
  labs(title="Distribution of CLV vs Monthly", 
       subtitle="With respect to Policy",
       fill="Response",
       y="CLV",
       x="Monthly Premium")

```

    Customers who adopted Personal policy plan are more and  L3 category is chosen highly among all the policy types.

```{r}
options(repr.plot.width=7, repr.plot.height=4)
GraphMonthsClaim <- ggplot(data, aes(x=Months.Since.Last.Claim, fill = Months.Since.Last.Claim))+ 
geom_bar(stat = "count")+
  labs(title="Frequency of Months Since last Claim",
       x="Months since last claim",
       y="Frequency")
 
GraphMonthsClaim
```


    From the graph, more customers made their claims recently.



```{r}
#Distribution of CLV with respect to Coverage
ggplot(data=data, aes(x=Customer.Lifetime.Value, fill=Coverage))+
  stat_bin(binwidth=10000,  position="dodge")+ 
  ylim(c(0,3000))+ 
  xlim(c(0,100000))+
  facet_wrap(~Coverage)+
  labs(title="Distribution of CLV", 
       subtitle="With respect to Coverage",
       fill="Response",
       x="CLV",
       y="Frequency")
       
```
      The distribution of CLV is more or less same.


```{r}
#With respect to State
ggplot(data=data, aes(y=Customer.Lifetime.Value, x=Monthly.Premium.Auto, color=Response ))+
  geom_point()+
  ylim(c(0,40000))+
  facet_wrap(~State)+
  labs(title="Distribution of CLV vs Monthly", 
       subtitle="With respect to State",
       fill="Response",
       y="CLV",
       x="Monthly Premium")
       
```


```{r}

#With respect to Renew Offer

ggplot(data=data, aes(y=Customer.Lifetime.Value, x=Monthly.Premium.Auto, color=Response ))+
  geom_point()+
  facet_wrap(~Renew.Offer.Type)+
  labs(title="Distribution of CLV vs Monthly", 
       subtitle="With respect to Renew Offer",
       fill="Response",
       y="CLV",
       x="Monthly Premium")
```

    There is a lack of positive response in offer type 4.





```{r}
ggplot(data=data, aes(y=Customer.Lifetime.Value, x=Monthly.Premium.Auto, color=Response ))+
  geom_point()+
  facet_wrap(~Number.of.Open.Complaints)+
  labs(title="Distribution of CLV vs Monthly", 
       subtitle="With respect to Number of Complaints",
       fill="Response",
       y="CLV",
       x="Monthly Premium")

```

    As the number of complaints increases, we can see that those customers are expected to be less valuable.

```{r}
ggplot(data=data, aes(y=Customer.Lifetime.Value, x=Months.Since.Policy.Inception ))+
  geom_point()+
  labs(title="Distribution of CLV", 
       subtitle="With respect to Months since policy Inception",
       fill="Response",
       y="CLV",
       x="Monthly Since Policy Inception")

```

```{r}
ggplot(data=data, aes(y=Customer.Lifetime.Value, x=Months.Since.Last.Claim ))+
  geom_point()+
  geom_jitter()+
  labs(title="Distribution of CLV", 
       subtitle="With respect to Months since last claim",
       fill="Response",
       y="CLV",
       x="Months since last claim")
```

    There doesnt seem to be any correlation between monthS since last claim and CLV.
```{r}
ggplot(data=data, aes(y=Customer.Lifetime.Value, x=Total.Claim.Amount ))+
  geom_point()+
  labs(title="Distribution of CLV", 
       subtitle="With respect to Total Claim",
       fill="Response",
       y="CLV",
       x="Total Claim Amount")

```


## Feature Engineering

Here we are going to select the significant features from the raw data and using it for predicting models.

##### CONVERTING TO FACTORS


```{r}

data$State <- factor(data$State)
data$Response <- factor(data$Response)
data$Coverage <- factor(data$Coverage,
                        levels=c('Basic','Extended','Premium'))
data$Education <- factor(data$Education,
                         levels=c('High School or Below','College','Bachelor',
                                  'Master','Doctor'))
data$EmploymentStatus <- factor(data$EmploymentStatus)
data$Gender <- factor(data$Gender)
data$Marital.Status <- factor(data$Marital.Status)
data$Number.of.Policies <- factor(data$Number.of.Policies)
data$Policy.Type <- factor(data$Policy.Type)
data$Policy <- factor(data$Policy)
data$Renew.Offer.Type <- factor(data$Renew.Offer.Type)
data$Sales.Channel <- factor(data$Sales.Channel)
data$Vehicle.Class <- factor(data$Vehicle.Class)
data$Vehicle.Size <- factor(data$Vehicle.Size,
                            levels=c('Small','Medsize','Large'))
```




```{r}
df <- data[,-c(1,7)]   # SELECTING THE COLUMNS EXCEPT 'CUSTOMER ID' AND 'EFFECT TO DATE'
```


```{r}
str(df)
```



```{r}
set.seed(123)
sample <- sample(c(TRUE, FALSE), 
                 nrow(df),
                 replace = T, 
                 prob = c(0.6,0.4))
df.train <- df[sample, ]
df.test <- df[!sample, ]

```
# VARIOUS MODELS AND THEIR PERFORMANCE GRAPH

```{r}


```

#### MODEL 1


Using multiple linear regression model to test the dependent variable clv with 'all other variables'. The fit of the model is assessed through r-squared value, which represents the proportion of variance explained. Here adjusted R2 = 0.6407 and R2 = 0.6443.
```{r MODEL 1, include=FALSE}


model1 <- lm ( data = df.train , Customer.Lifetime.Value~ .)
summary(model1)

```


```{r}
rsquare(model1,df.train)
rsquare(model1,df.test)
```

```{r}
plot(model1)
```

```{r include=FALSE}

# USING STEPWISE REGRESSION TO FIND THE MOST EFFECTIVE VARIABLES.
 step<- stepAIC ( model1 , direction = "both")  
```
#### MODEL 2
Here, we used AIC as the criterion to select the variables and got an adjusted R squared value of 0.6415.


###### Features Selected -
- Response
- Education
- Employment Status 
- Gender 
- Marital.Status 
- Monthly.Premium.Auto 
- Months.Since.Last.Claim 
- Number.of.Open.Complaints 
- Number.of.Policies 
- Vehicle.Class

```{r include=FALSE}

model2 <- lm ( data = df.train , Customer.Lifetime.Value~Response 
               + Education 
               + EmploymentStatus 
               + Gender 
               + Marital.Status 
               + Monthly.Premium.Auto 
               + Months.Since.Last.Claim 
               + Number.of.Open.Complaints 
               + Number.of.Policies 
               + Vehicle.Class)

summary(model2)

```


```{r}
rsquare(model2,df.train)
rsquare(model2,df.test)
```
```{r}
plot(model2)
```
#### MODEL 3
#### Log Transformation


Using log transformation to treat outliers in variables like clv and monthly premium auto.

###### Features Selected -
- Response
- Education
- Employment Status 
- Gender 
- Marital.Status 
- log1p(Monthly.Premium.Auto) 
- Months.Since.Last.Claim 
- Number.of.Open.Complaints 
- Number.of.Policies 
- Vehicle.Class

```{r include=FALSE}

model3 <- lm ( data = df.train , log1p(Customer.Lifetime.Value) ~ Response 
               + Education 
               + EmploymentStatus 
               + Gender 
               + Marital.Status 
               + log1p(Monthly.Premium.Auto) 
               + Months.Since.Last.Claim 
               + Number.of.Open.Complaints 
               + Number.of.Policies 
               + Vehicle.Class)

summary(model3)

```


```{r}
plot(model3)
```

#### MODEL 4
#### CAPPING/CLIPPING TRANSFORMATION

Another outlier treatment, the clipping method is done on the dependent variable. Then the linear model results an adjusted R squared value of 0.6874. This is higher than our base model, suggesting clipping method does a better job in explaining the variance in clv.

###### Features Selected -
- All variables from model2, also Monthly premium auto was capped.
```{r include=FALSE}


# USING CAPPING/CLIPPING TRANSFORMATION FOR OUTLIER TREATMENT. 

x <- df.train$Customer.Lifetime.Value
qnt <- quantile(x, probs=c(.25, .75), na.rm = T)
caps <- quantile(x, probs=c(.05, .97), na.rm = T)
H <- 1.5 * IQR(x, na.rm = T)

x[x < (qnt[1] - H)] <- caps[1]
x[x > (qnt[2] + H)] <- caps[2]

df.train$Customer.Lifetime.Value <- x

y <- df.train$Monthly.Premium.Auto
qnt <- quantile(y, probs=c(.25, .75), na.rm = T)
caps <- quantile(y, probs=c(.05, .97), na.rm = T)
H <- 1.5 * IQR(y, na.rm = T)

y[y < (qnt[1] - H)] <- caps[1]
y[y > (qnt[2] + H)] <- caps[2]

df.train$Monthly.Premium.Auto <- y


model4 <- lm(data= df.train , Customer.Lifetime.Value ~ Response 
             + Education 
             + EmploymentStatus 
             + Gender 
             + Marital.Status 
             + Monthly.Premium.Auto 
             + Months.Since.Last.Claim 
             + Number.of.Open.Complaints 
             + Number.of.Policies 
             + Vehicle.Class)
summary(model4)
```



```{r}
rsquare(model4,df.train)
rsquare(model4,df.test)

```
```{r}
plot(model4)
```


#### MODEL 5
Clustering methods like k mode and k means are used to group similar inputs. These clusters are then passed to a linear model. All the variables were used in this model.
Here, adjusted R2 = 0.6871.

###### Features Selected -

- All variables from model1 and additional variables cat.clusters and num.clusters
```{r include=FALSE}
data.for.cat.clustering <- data[,-c(1,3,7,10,13,14,15,22)]
data.for.num.clustering <- data[,c(10,13,14,15,22)]

set.seed(2348)
cat.clusters <- kmodes(data.for.cat.clustering,6)
num.clusters <- kmeans(data.for.num.clustering,8)

data$cat.clusters <- cat.clusters$cluster
data$num.clusters <- num.clusters$cluster

```


```{r include=FALSE}


model5 <- lm((Customer.Lifetime.Value)~.,
               data=df.train)
summary(model5)
```

```{r}
plot(model5)
```

```{r}
rsquare(model5,df.train)
rsquare(model5,df.test)
```

```{r include=FALSE}
step<- stepAIC ( model5, direction = "both")

# result 

               #   Coverage 
               # + EmploymentStatus 
               # + Gender 
               # + Marital.Status 
               # + Monthly.Premium.Auto 
               # + Months.Since.Last.Claim 
               # + Number.of.Open.Complaints 
               # + Number.of.Policies 
               # + Vehicle.Class
```


#### MODEL 6
Variables for this model were selected by carrying out stepwise regression on the previous model. Here, adjusted R2 = 0.6878.

###### Features Selected -

- Coverage 
- EmploymentStatus 
- Gender 
- Marital.Status 
- Monthly.Premium.Auto 
- Months.Since.Last.Claim 
- Number.of.Open.Complaints 
- Number.of.Policies 
- Vehicle.Class
```{r include=FALSE}
model6 <- lm((Customer.Lifetime.Value)~
                 Coverage 
               + EmploymentStatus 
               + Gender 
               + Marital.Status 
               + Monthly.Premium.Auto 
               + Months.Since.Last.Claim 
               + Number.of.Open.Complaints 
               + Number.of.Policies 
               + Vehicle.Class
               ,data=df.train)


summary(model6)
```


```{r}
rsquare(model6,df.train)
rsquare(model6,df.test)
```

```{r}
plot(model6)
```



#### MODEL 7

In this model, an additional column was included where the square of Monthly Premium Auto was used. But the additional variable was found to be insignificant (p value > 0.05).

###### Features Selected -

- Coverage 
- EmploymentStatus 
- Gender 
- Marital.Status 
- Monthly.Premium.Auto 
- Monthly.Premium.Auto**2
- Months.Since.Last.Claim 
- Number.of.Open.Complaints 
- Number.of.Policies 
- Vehicle.Class

```{r include=FALSE}



model7 <- lm((Customer.Lifetime.Value)~
               Coverage 
               + EmploymentStatus 
               + Gender 
               + Marital.Status 
               + Monthly.Premium.Auto + I(Monthly.Premium.Auto**2)
               + Months.Since.Last.Claim 
               + Number.of.Open.Complaints 
               + Number.of.Policies 
               + Vehicle.Class
               ,data=df.train)

summary(model7)

```


```{r}
rsquare(model7,df.train)
rsquare(model7,df.test)
```
```{r}
plot(model7)
```


#### MODEL 8
We used Random forest regressor to model the data. It overfits our training dataset.

###### Features Selected - 

- All the features in model1
```{r include=FALSE}
# RANDOM FOREST

set.seed(52)
model8 <- randomForest((Customer.Lifetime.Value)~.,data=df.train)


```

```{r include=FALSE}
print(model8) 
# Importance of each predictor.
print(importance(model8,type = 2))
```

```{r include=FALSE}
summary(model8)
```

```{r}
rsquare(model8,df.train)

```
```{r}
rsquare(model8,df.test)
```

```{r}
plot(model8)
```
 

### MODEL PERFORMANCE OF FINAL MODEL

ASSESSING ACCURACY OF MODELS

Comparing all the models, we can see that adjusted R squared is highest for model 6. 
The result suggests that the variables can explain about 69% of variability in our clv data.



```{r}
model6 <- lm((Customer.Lifetime.Value)~
                 Coverage 
               + EmploymentStatus 
               + Gender 
               + Marital.Status 
               + Monthly.Premium.Auto 
               + Months.Since.Last.Claim 
               + Number.of.Open.Complaints 
               + Number.of.Policies 
               + Vehicle.Class
               ,data=df.train)


summary(model6)
```


```{r}
# CROSS VALIDATION

# Train the model
set.seed(123) 
train.control <- trainControl(method = "cv", number = 10)

model6cv <- train(Customer.Lifetime.Value~
                 Coverage 
               + EmploymentStatus 
               + Gender 
               + Marital.Status 
               + Monthly.Premium.Auto 
               + Months.Since.Last.Claim 
               + Number.of.Open.Complaints 
               + Number.of.Policies 
               + Vehicle.Class ,data=df.train, method = "lm",
               trControl = train.control)

# Summarize the results
print(model6cv)
```


```{r}
plot(model6)
```


Graph 1: Residual v/s Fitted - 
- Used to draw insights on outliers
- A funnel shaped graph implies heteroscedasticity. 
- Since the graph is not funnel shaped, our model is homoscedastic(This was achieved using capping method of outlier treatment).


Graph 2: QQ plot - 
- Used to validate assumption of normal distribution in a dataset.
- if the line is straight, then it implies a normal distribution.
- The deviation from straight line implies absence of normality.

Graph 3: Scale Location - 
- Used to detect homoscedasticity of errors.
- Discernible patterns imply non-normally distributed errors
- The graph has no discernible pattern, so the errors are normally distributed.

Graph 4: Residual v/s Leverage -
- Useful in finding the points which have more influence than other points.
- Also known as Cook's distance plot.
- Using this plot, we removed three inputs from our model and it resulted in a better output (improved adj r squared value).This implies that the three points were outliers and had significant influence on our model.


```{r}
model6 <- lm((Customer.Lifetime.Value)~
                 Coverage 
               + EmploymentStatus 
               + Gender 
               + Marital.Status 
               + Monthly.Premium.Auto 
               + Months.Since.Last.Claim 
               + Number.of.Open.Complaints 
               + Number.of.Policies 
               + Vehicle.Class
               ,data=df.train[-c(6183, 6873,1384),])


summary(model6)
```


# Conclusions

#### From The EDA:

1.    The ABC insurance company benefits from clients that are: employed, married, live in suburban areas with vehicles of four-door and Medsize.
2.    The data was severely left sided askew denoting that majority of the clients represented in the data had low CLV and very few had high CLV. To reduce the effect of the outliers, the log value of the CLV was taken.
3.    Clients who had used the sales channel through an agent have a considerably high CLV. Showing that agents have are better at selling car insurances.
4.    Some cases where the number of complaints that were unresolved showed lower CLV. 

#### From The Model:
1.	As seen Above the model with the best performance was model 6.
2.	The result suggests that the variables can explain about 69% of variability in our clv data.
3.    And the train and test score had the least difference, with train of 0.6892 and test of 0.6203.
4.    The features which played the main role in determining the CLV were, Coverage, Employment Status, Gender, Marital Status, Monthly Premium Auto, Months Since Last Claim, Number of Open Complaints, Number of Policies and Vehicle Class.

 
#### Additions that would have help analysis:
1.    Details regarding the type of policies when they had taken multiple policies.
2.    Details about the frequency of claims Made would have assisted in the understanding of the CLV.
3.    As there were a considerable number of clients who have taken policies, that are unemployment (with income = 0). Details on the fact that these clients had taken policies on the name of their guardians (Young adults/new drivers) would add on as to their target audience better understanding the CLV amount.

# References


http://www.sumsar.net/blog/2015/03/a-speed-comparison-between-flexible-linear-regression-alternatives-in-r/

http://r-statistics.co/Variable-Selection-and-Importance-With-R.html

https://r-statistics.co/Outlier-Treatment-With-R.html

http://www.sthda.com/english/articles/38-regression-model-validation/157-cross-validation-essentials-in-r/
 
https://www.tutorialspoint.com/r/r_random_forest.htm
 
 https://www.gormanalysis.com/blog/r-introduction-to-factors-tutorial/

# Work Distributions

Though mentioned below are the division of tasks, each member of the team contributed towards each other's task. Each of us had done personal EDA, feature engineering and initial model development. Of those the best were selected, further developed and reported.

Marion (20BDA04): Along with Gargi, developed the final structure of the Models and performance.

Bismi (20BDA07): Along with Lakshmi, developed the final structure of the EDA and Feature 
engineering. Compilation of the final report.

Lakshmi (20BDA09): Along with Bismi, developed the final structure of the EDA and Feature engineering. Compilation of the final report.

Glennis (20BDA24): Provided the final excerpt for the conclusions and additions to the concept.

Gargi (20BDA55): Along with Marion, developed the final structure of the Models and performance.

Ajay (20BDA64): Provided the base concept for the structure of the model. In addition also added the final excerpt of about CLV 




